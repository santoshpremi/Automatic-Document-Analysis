{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZ/hpR7dpzAQOIGe2+tFn3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santoshpremi/Automatic-Document-Analysis/blob/main/Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this tutorial, we’ll explore a powerful approach to compare two PDF documents.**\n",
        "\n",
        "**Table of Contents**\n",
        "1. Setup Environment\n",
        "2. Text Extraction from PDFs\n",
        "3. Word-Level Differences\n",
        "4. Sentence-Level Comparison\n",
        "5. Semantic Similarity Analysis"
      ],
      "metadata": {
        "id": "RVeBMvqDH_Pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Setup Environment**\n",
        "\n",
        "Google Drive Mount: This allows access to PDF files stored in your Google Drive.\n"
      ],
      "metadata": {
        "id": "iGOCOUzQIbtg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g-9ZThl0MYEz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tesseract OCR:** Handle scanned PDFs where text extraction isn’t possible.\n",
        "\n",
        "**Libraries:**\n",
        "\n",
        "**PyMuPDF (fitz):**  Extracts text from standard PDFs. <br>\n",
        "**pytesseract:** Integrates Tesseract for OCR. <br>\n",
        "**spaCy:** Splits text into sentences for granular analysis. <br>\n",
        "**transformers:**  Provides BERT for semantic similarity calculations."
      ],
      "metadata": {
        "id": "kx-_H8FuI0-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract PyMuPDF pdfplumber transformers spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "s8yUoBnXMemc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import fitz\n",
        "import difflib\n",
        "import spacy\n",
        "import pytesseract\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io"
      ],
      "metadata": {
        "id": "hSdb1bdUsYKb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace these paths with your PDF locations in Google Drive\n",
        "pdf_v1_path = '/content/drive/MyDrive/Adhikari_Cover_letter.pdf'\n",
        "pdf_v2_path = '/content/drive/MyDrive/Adhikari_Cover_letter_5.pdf'"
      ],
      "metadata": {
        "id": "qqUJpqMBsari"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Text Extraction from PDFs**\n",
        "\n",
        "Documents often contain text or images. Our extraction function handles both cases:"
      ],
      "metadata": {
        "id": "5tU53HQKN8zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== DOCUMENT COMPARISON ====================\n",
        "def extract_text(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        # Try text extraction first\n",
        "        page_text = page.get_text()\n",
        "        if page_text.strip():\n",
        "            text += page_text\n",
        "        else:\n",
        "            # Fallback to OCR\n",
        "            pix = page.get_pixmap()\n",
        "            img = Image.open(io.BytesIO(pix.tobytes()))\n",
        "            text += pytesseract.image_to_string(img)\n",
        "    return text\n",
        "# Load PDFs from Drive\n",
        "text1 = extract_text(pdf_v1_path)\n",
        "text2 = extract_text(pdf_v2_path)"
      ],
      "metadata": {
        "id": "UG-B1tF8rRxe",
        "collapsed": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How It Works:**\n",
        "\n",
        "**1. Text Extraction:** fitz retrieves text directly from PDF pages. <br>\n",
        "**2. OCR Fallback:** If a page has no extractable text (e.g., scanned PDF), it converts the page to an image and uses Tesseract OCR. <br>\n",
        "**3. Efficiency:** Combines both methods to ensure no content is missed."
      ],
      "metadata": {
        "id": "i3cwcnJHOp3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Word-Level Differences:** <br>\n",
        "Identify additions, deletions, and modifications at the word level with color coding:"
      ],
      "metadata": {
        "id": "OlOxnCNfOXCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== VISUAL DIFF DISPLAY ====================\n",
        "def print_colored_diff(old_text, new_text):\n",
        "    \"\"\"\n",
        "    Shows word-level differences with color coding\n",
        "    - Red: Removed text\n",
        "    - Green: Added text\n",
        "    \"\"\"\n",
        "    d = difflib.Differ()\n",
        "    diff = d.compare(old_text.split(), new_text.split())\n",
        "\n",
        "    current_line = []\n",
        "    line_length = 0\n",
        "    for word in diff:\n",
        "        # Format word with color\n",
        "        if word.startswith('- '):\n",
        "            formatted_word = f\"\\033[91m{word[2:]}\\033[0m\"\n",
        "        elif word.startswith('+ '):\n",
        "            formatted_word = f\"\\033[92m{word[2:]}\\033[0m\"\n",
        "        elif word.startswith('? '):\n",
        "            continue\n",
        "        else:\n",
        "            formatted_word = word[2:]\n",
        "\n",
        "        # Check line length and wrap text\n",
        "        if line_length + len(formatted_word) > 80:\n",
        "            print(' '.join(current_line))\n",
        "            current_line = []\n",
        "            line_length =0\n",
        "\n",
        "        current_line.append(formatted_word)\n",
        "        line_length += len(formatted_word) + 1\n",
        "\n",
        "    if current_line:\n",
        "        print(' '.join(current_line))"
      ],
      "metadata": {
        "id": "vmVF5tYZMMHJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Color Coding:** Red for removed words, green for added words. <br>\n",
        "**Line Wrapping:** Ensures output remains readable by limiting line length."
      ],
      "metadata": {
        "id": "FBZ-ivCgPDbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**4. Sentence-Level Comparison:**\n",
        "Analyze changes at the sentence level to understand structural edits:"
      ],
      "metadata": {
        "id": "V6H_-Y9lPQ-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load English NLP model for sentence splitting\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# ==================== SENTENCE-LEVEL ANALYSIS ====================\n",
        "def compare_sentences(text1, text2):\n",
        "    \"\"\"\n",
        "    Compare documents at sentence level using spaCy with inline coloring\n",
        "    \"\"\"\n",
        "    doc1 = nlp(text1)\n",
        "    doc2 = nlp(text2)\n",
        "\n",
        "    sentences1 = [sent.text for sent in doc1.sents]\n",
        "    sentences2 = [sent.text for sent in doc2.sents]\n",
        "\n",
        "    matcher = difflib.SequenceMatcher(None, sentences1, sentences2)\n",
        "    count_sentence = 1\n",
        "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
        "        if tag == 'replace':\n",
        "            original = ' '.join(sentences1[i1:i2])\n",
        "            modified = ' '.join(sentences2[j1:j2])\n",
        "\n",
        "            print(f\"{count_sentence}.MODIFIED SENTENCES\")\n",
        "            count_sentence += 1\n",
        "            print(\"\\nOriginal Version (removed content in red):\\n\" + \"─\" * 40)\n",
        "            # Show original with deletions colored\n",
        "            d = difflib.Differ()\n",
        "            diff_original = [token for token in d.compare(original.split(), modified.split())\n",
        "                             if token.startswith(('- ', '  '))]\n",
        "            print_colored_diff(original, modified)\n",
        "\n",
        "            print(\"\\nNew Version (added content in green):\\n\" + \"─\" * 40)\n",
        "            # Show modified with additions colored\n",
        "            d = difflib.Differ()\n",
        "            diff_modified = [token for token in d.compare(original.split(), modified.split())\n",
        "                             if token.startswith(('+ ', '  '))]\n",
        "            print_colored_diff(original, modified)\n",
        "            print(\"\\n\")\n",
        "\n",
        "        elif tag == 'delete':\n",
        "            print(\"DELETED SENTENCES \".center(80, '─'))\n",
        "            print('\\n'.join([f\"• \\033[91m{sent}\\033[0m\" for sent in sentences1[i1:i2]]))\n",
        "            print(\"\\n\" + \"─\" * 80)\n",
        "\n",
        "        elif tag == 'insert':\n",
        "            print(\"ADDED SENTENCES\".center(80, '─'))\n",
        "            print('\\n'.join([f\"• \\033[92m{sent}\\033[0m\" for sent in sentences2[j1:j2]]))\n",
        "            print(\"\\n\" + \"─\" * 80)"
      ],
      "metadata": {
        "id": "p_rGM0x-MVMA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Workflow:**\n",
        "**Sentence Splitting:** spaCy divides text into sentences. <br>\n",
        "**Sequence Matching:** difflib identifies replacements, deletions, and insertions. <br>\n",
        "**Visual Feedback:** Highlights modified sentences and lists added/removed content."
      ],
      "metadata": {
        "id": "6Dd6MptXPhMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Semantic Similarity Analysis**\n",
        "Measure how meaningfully similar two documents are using BERT embeddings:"
      ],
      "metadata": {
        "id": "NGz6bsiJP3DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== SEMANTIC SIMILARITY ANALYSIS ====================\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "def semantic_similarity(text1, text2):\n",
        "    embedding1 = get_embedding(text1)\n",
        "    embedding2 = get_embedding(text2)\n",
        "    return cosine_similarity(embedding1, embedding2)[0][0]"
      ],
      "metadata": {
        "id": "RlEc4c3tMlze"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT Embeddings:** Converts text into numerical vectors capturing contextual meaning. <br>\n",
        "**Cosine Similarity:** Computes similarity between vectors (0 = dissimilar, 1 = identical). <br>\n",
        "**Use Case:** Detects paraphrasing or structural changes that aren’t visible in word/sentence diffs."
      ],
      "metadata": {
        "id": "lNLRAZ4wQAED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== MAIN EXECUTION ====================\n",
        "# Show detailed differences\n",
        "print(\" WORD-LEVEL CHANGES \".center(80, '═'))\n",
        "print_colored_diff(text1, text2)\n",
        "print(\"\\n\")\n",
        "# Show sentence-level analysis\n",
        "print(\" SENTENCE-LEVEL CHANGES \".center(80, '═'))\n",
        "compare_sentences(text1, text2)\n",
        "\n",
        "# Calculate and show semantic similarity\n",
        "similarity_score = semantic_similarity(text1, text2)\n",
        "\n",
        "# Show similarity-based recommendation\n",
        "print(f\"SEMANTIC SIMILARITY ANALYSIS:\".center(80, '═'))\n",
        "print(f\"Semantic Similarity Score: {similarity_score:.2f}\")\n",
        "\n",
        "if similarity_score > 0.85:\n",
        "    print(\"✅ Documents are highly similar semantically\")\n",
        "elif similarity_score > 0.7:\n",
        "    print(\"⚠️ Documents have moderate semantic differences\")\n",
        "else:\n",
        "    print(\"❌ Documents are significantly different semantically\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9DFZZnYQaFP",
        "outputId": "935d0d49-5ce2-4d60-cbe3-26c72e228862"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "══════════════════════════════ WORD-LEVEL CHANGES ══════════════════════════════\n",
            "Dear Hiring Team, I am writing to express my sincere interest in the Software\n",
            "Engineering (Working Student) position at Fulfin. As a Master’s student in\n",
            "Computer Science at Julius Maximilians University Wurzburg, I have developed\n",
            "proficiency in Python, PostgreSQL, and full-stack development, which I believe\n",
            "align well with the \u001b[91mrequirements\u001b[0m \u001b[92mlending\u001b[0m of this role.\n",
            "Relevant Experience and Skills Python & JavaScript Development: I have extensive\n",
            "experience in Python, including the development of machine learning models. For\n",
            "instance, I created Background Remover AI using PyTorch, which leverages Python\n",
            "for backend processing. This project honed my ability to develop and implement\n",
            "algorithms efficiently. Full-Stack Development: During my software developer\n",
            "role at Real Time Solutions, I have built and maintained full-stack applications\n",
            "using JavaScript Reactjs and Python. Collaboration & Problem-Solving: During my\n",
            "software developer role at Real Time Solutions, I collaborated with\n",
            "cross-functional teams to gather requirements and prototype solutions. I thrive\n",
            "in environments that require analytical thinking and proactive collaboration.\n",
            "Why I am a Strong Fit for Fulfin Fulfin’s focus on revolutionizing access to\n",
            "credit through cutting-edge technology resonates with my passion for leveraging\n",
            "software to solve real-world problems. I am particularly drawn to the\n",
            "opportunity to work closely with the credit risk team and contribute to the\n",
            "development of algorithms and scorecards that drive informed decision-making.\n",
            "Availability and Commitment I am available to start immediately and can commit\n",
            "to a flexible schedule of 20–25 hours per week, ensuring minimal disruption to\n",
            "my academic responsibilities. Thank you for considering my application. I look\n",
            "forward to the opportunity to discuss how my skills and experiences can\n",
            "contribute to Fulfin’s mission of transforming small business \u001b[91mlending.\u001b[0m\n",
            "\u001b[92mrequirements.\u001b[0m Best regards, Santosh Premi Adhikari +49 15754394063 |\n",
            "santoshadhikaripremi@gmail.com | Portfolio\n",
            "\n",
            "\n",
            "════════════════════════════ SENTENCE-LEVEL CHANGES ════════════════════════════\n",
            "1.MODIFIED SENTENCES\n",
            "\n",
            "Original Version (removed content in red):\n",
            "────────────────────────────────────────\n",
            "As a Master’s student in Computer Science at Julius Maximilians University\n",
            "Wurzburg, I have developed proficiency in Python, PostgreSQL, and full-stack\n",
            "development, which I believe align well with the \u001b[91mrequirements\u001b[0m\n",
            "\u001b[92mlending\u001b[0m of this role.\n",
            "\n",
            "New Version (added content in green):\n",
            "────────────────────────────────────────\n",
            "As a Master’s student in Computer Science at Julius Maximilians University\n",
            "Wurzburg, I have developed proficiency in Python, PostgreSQL, and full-stack\n",
            "development, which I believe align well with the \u001b[91mrequirements\u001b[0m\n",
            "\u001b[92mlending\u001b[0m of this role.\n",
            "\n",
            "\n",
            "2.MODIFIED SENTENCES\n",
            "\n",
            "Original Version (removed content in red):\n",
            "────────────────────────────────────────\n",
            "I look forward to the opportunity to discuss how my skills and experiences can\n",
            "contribute to Fulfin’s mission of transforming small business \u001b[91mlending.\u001b[0m\n",
            "\u001b[92mrequirements.\u001b[0m\n",
            "\n",
            "New Version (added content in green):\n",
            "────────────────────────────────────────\n",
            "I look forward to the opportunity to discuss how my skills and experiences can\n",
            "contribute to Fulfin’s mission of transforming small business \u001b[91mlending.\u001b[0m\n",
            "\u001b[92mrequirements.\u001b[0m\n",
            "\n",
            "\n",
            "═════════════════════════SEMANTIC SIMILARITY ANALYSIS:══════════════════════════\n",
            "Semantic Similarity Score: 1.00\n",
            "✅ Documents are highly similar semantically\n"
          ]
        }
      ]
    }
  ]
}